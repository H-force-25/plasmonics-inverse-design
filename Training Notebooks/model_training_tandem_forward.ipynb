{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tapxaurdc5rp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import and modify dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FMk3vku6c9te",
        "outputId": "116cafa1-8ceb-4688-9e75-405a0dff9ecc"
      },
      "outputs": [],
      "source": [
        "ds = pd.read_csv('../Dataset/data_abs.csv', header=None)\n",
        "ds = ds[ds[4] == 1] # Select data for water media\n",
        "ds = ds[ds[1] != 0] # Select only core-shell particles\n",
        "ds = ds.sample(frac=1).reset_index(drop=True) # Randomize dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzlCyWS-fsUo"
      },
      "outputs": [],
      "source": [
        "num_mats = 11 # Total number of materials used (including \"empty\")\n",
        "spectra = np.array(ds.iloc[:, 5:])/255 # Normalized spectra\n",
        "\n",
        "m1 = np.array(ds[[0]]) # Core material ids\n",
        "m2 = np.array(ds[[1]]) # Shell material ids\n",
        "t1 = np.array(ds[[2]])/100 # Normalized core thickness\n",
        "t2 = np.array(ds[[3]])/100 # Normalized shell thickness\n",
        "\n",
        "geo = np.hstack((m1, m2, t1, t2)) # Geometry parameters\n",
        "\n",
        "test_split = int(0.95*ds.shape[0]) # Number of samples separated for testing after training\n",
        "\n",
        "# Training output\n",
        "y_train = spectra[:test_split]\n",
        "y_train = tf.expand_dims(y_train, axis=-1)\n",
        "\n",
        "# Training features\n",
        "x_train_m1 = keras.utils.to_categorical(m1[:test_split])\n",
        "x_train_m1 = tf.expand_dims(x_train_m1, axis=1)\n",
        "x_train_m2 = keras.utils.to_categorical(m2[:test_split])\n",
        "x_train_m2 = tf.expand_dims(x_train_m2, axis=1)\n",
        "x_train_t1 = t1[:test_split]\n",
        "x_train_t1 = tf.expand_dims(x_train_t1, axis=-1)\n",
        "x_train_t2 = t2[:test_split]\n",
        "x_train_t2 = tf.expand_dims(x_train_t2, axis=-1)\n",
        "x_train = geo[:test_split]\n",
        "x_train = tf.expand_dims(x_train, axis=-1)\n",
        "\n",
        "# Testing output\n",
        "y_test = spectra[test_split:]\n",
        "y_test = tf.expand_dims(y_test, axis=-1)\n",
        "\n",
        "# Testing features\n",
        "x_test_m1 = keras.utils.to_categorical(m1[test_split:])\n",
        "x_test_m1 = tf.expand_dims(x_test_m1, axis=1)\n",
        "x_test_m2 = keras.utils.to_categorical(m2[test_split:])\n",
        "x_test_m2 = tf.expand_dims(x_test_m2, axis=1)\n",
        "x_test_t1 = t1[test_split:]\n",
        "x_test_t1 = tf.expand_dims(x_test_t1, axis=-1)\n",
        "x_test_t2 = t2[test_split:]\n",
        "x_test_t2 = tf.expand_dims(x_test_t2, axis=-1)\n",
        "x_test = geo[test_split:]\n",
        "x_test = tf.expand_dims(x_test, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-8ewFNLkmRG"
      },
      "source": [
        "# resNeXt block\n",
        "\n",
        "A 1D resNeXt block that is subsequently used to define the full model. The concept modifies the classical res-block using grouped convolutions and bottleneck layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tC9JG-dekkIE"
      },
      "outputs": [],
      "source": [
        "def resNeXt_block(x_in, N_filter, N_groups, N_bottleneck, kernel_size=3, strides=1,\n",
        "                   conv_layer=keras.layers.Conv1D, alpha=0.3, with_BN=True):\n",
        "\n",
        "    # Residual connection\n",
        "    if x_in.shape[-1] != N_filter or strides != 1:\n",
        "        # If input != output dimension, add BN/ReLU/conv. into shortcut\n",
        "        conv_shortcut = conv_layer(\n",
        "            filters=N_filter, kernel_size=1, strides=strides, padding='same')(x_in)\n",
        "    else:\n",
        "        # Else use bare input as shortcut\n",
        "        conv_shortcut = x_in\n",
        "    \n",
        "    if with_BN:\n",
        "        conv_shortcut = keras.layers.BatchNormalization()(conv_shortcut)\n",
        "\n",
        "    # ResNeXt path\n",
        "    N_bottleneck_filters = int(N_filter * N_bottleneck)\n",
        "    x = x_in\n",
        "\n",
        "    x = conv_layer(filters=N_bottleneck_filters, kernel_size=1, strides=1,\n",
        "                            padding='same', use_bias=not with_BN)(x)\n",
        "    if with_BN:\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.LeakyReLU(alpha)(x)\n",
        "\n",
        "    x = conv_layer(filters=N_bottleneck_filters, kernel_size=kernel_size,\n",
        "                   strides=strides, padding='same',\n",
        "                   groups=N_bottleneck_filters//N_groups, use_bias=not with_BN)(x)\n",
        "    if with_BN:\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.LeakyReLU(alpha)(x)\n",
        "\n",
        "    x = conv_layer(filters=N_filter, kernel_size=1, strides=1,\n",
        "                   padding='same', use_bias=not with_BN)(x)\n",
        "    if with_BN:\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    # Add residual and main and apply a further activation\n",
        "    x = keras.layers.Add()([x, conv_shortcut])\n",
        "    x = keras.layers.LeakyReLU(alpha)(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M-0Ci-zkru_"
      },
      "source": [
        "# Define the resNeXt model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM-gxwc9krZ4",
        "outputId": "6ee2015b-8f65-4aca-d109-1f0b684fa9ba"
      },
      "outputs": [],
      "source": [
        "N_blocks = 2\n",
        "\n",
        "# Input features\n",
        "design_in_m1 = keras.Input(shape=x_train_m1.shape[1:], name='design_in_m1')\n",
        "design_in_m2 = keras.Input(shape=x_train_m2.shape[1:], name='design_in_m2')\n",
        "design_in_t1 = keras.Input(shape=x_train_t1.shape[1:], name='design_in_t1')\n",
        "design_in_t2 = keras.Input(shape=x_train_t2.shape[1:], name='design_in_t2')\n",
        "\n",
        "x_m1 = design_in_m1\n",
        "x_m2 = design_in_m2\n",
        "x_t1 = design_in_t1\n",
        "x_t2 = design_in_t2\n",
        "\n",
        "x_1 = keras.layers.Concatenate(axis=-1)([x_m1, x_t1])\n",
        "x_2 = keras.layers.Concatenate(axis=-1)([x_m2, x_t2])\n",
        "x = keras.layers.Concatenate(axis=1)([x_1, x_2])\n",
        "\n",
        "x = tf.keras.layers.ZeroPadding1D((1,1))(x) # 2 --> 4\n",
        "\n",
        "for i in range(N_blocks):\n",
        "    x = resNeXt_block(x, N_filter=256, N_groups=8, N_bottleneck=4, strides=1)\n",
        "x = keras.layers.UpSampling1D()(x) # 8 --> 16\n",
        "\n",
        "for i in range(N_blocks):\n",
        "    x = resNeXt_block(x, N_filter=128, N_groups=8, N_bottleneck=4, strides=1)\n",
        "x = keras.layers.UpSampling1D(5)(x) # 8 --> 40\n",
        "\n",
        "for i in range(N_blocks):\n",
        "    x = resNeXt_block(x, N_filter=64, N_groups=8, N_bottleneck=4, strides=1)\n",
        "x = keras.layers.UpSampling1D(5)(x) # 40 --> 200\n",
        "\n",
        "for i in range(N_blocks):\n",
        "    x = resNeXt_block(x, N_filter=32, N_groups=8, N_bottleneck=4, strides=1)\n",
        "\n",
        "x = resNeXt_block(x, N_filter=32, N_groups=32,\n",
        "                  N_bottleneck=4, strides=1, with_BN='False')\n",
        "\n",
        "# Output\n",
        "resnext_output = keras.layers.Conv1D(\n",
        "    filters=1, kernel_size=1, padding='same')(x)\n",
        "\n",
        "resnext_model = keras.models.Model(\n",
        "    inputs=[design_in_m1,design_in_m2, design_in_t1, design_in_t2], outputs=resnext_output, name='resnext_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeeyBd2pPvhG"
      },
      "outputs": [],
      "source": [
        "def residual_block(x_in, N_filter, kernel_size=3, strides=1,\n",
        "                   conv_layer=keras.layers.Conv1D, alpha=0.3,\n",
        "                   with_BN=False):\n",
        "\n",
        "    # Residual connection\n",
        "    if x_in.shape[-1] != N_filter or strides != 1:\n",
        "        # If input != output dimension, add BN/ReLU/conv. into shortcut\n",
        "        conv_shortcut = conv_layer(\n",
        "            filters=N_filter, kernel_size=1, strides=strides, padding='same')(x_in)\n",
        "    else:\n",
        "        # Else use bare input as shortcut\n",
        "        conv_shortcut = x_in\n",
        "\n",
        "    # Convolutional path\n",
        "    x = x_in\n",
        "\n",
        "    x = conv_layer(filters=N_filter, kernel_size=1, strides=1,\n",
        "                   padding='same', use_bias=not with_BN)(x)\n",
        "    if with_BN:\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.LeakyReLU(alpha)(x)\n",
        "\n",
        "    x = conv_layer(filters=N_filter, kernel_size=kernel_size,\n",
        "                   strides=strides, padding='same', use_bias=not with_BN)(x)\n",
        "    if with_BN:\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.LeakyReLU(alpha)(x)\n",
        "\n",
        "    x = conv_layer(filters=N_filter, kernel_size=1, strides=1,\n",
        "                   padding='same', use_bias=not with_BN)(x)\n",
        "    if with_BN:\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    # Add residual and main and apply a further activation\n",
        "    x = keras.layers.Add()([x, conv_shortcut])\n",
        "    x = keras.layers.LeakyReLU(alpha)(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg1x-bWgk3bh"
      },
      "source": [
        "# Train the resNeXt model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmRZQ4TEkkUm",
        "outputId": "93ac6961-eb54-4599-faf3-f25168d0ce05"
      },
      "outputs": [],
      "source": [
        "# Compile with optimizer and cost function\n",
        "resnext_model.compile(optimizer=keras.optimizers.AdamW(learning_rate=0.01),\n",
        "                      loss='mse')\n",
        "\n",
        "# Automatic learning rate reduction on loss plateau\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=1/2, patience=4, verbose=1)\n",
        "\n",
        "# Callback for early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True)\n",
        "\n",
        "# Assemble training configurations\n",
        "train_kwargs = dict(x=[x_train_m1, x_train_m2, x_train_t1, x_train_t2],\n",
        "                    y=y_train, validation_split=0.2,\n",
        "                    epochs=16, callbacks=[reduce_lr, early_stop])\n",
        "\n",
        "# Fit the model with BN --> increasing batchsize schdedule\n",
        "hist = None # Global history after BS incrase\n",
        "for i in range(4): # 4x16 epochs, increasing batchsize\n",
        "    _h = resnext_model.fit(batch_size=(16 * 2**i), **train_kwargs)\n",
        "    if hist is None:\n",
        "        hist = _h\n",
        "    else:\n",
        "        # Update history\n",
        "        for k in hist.history:\n",
        "            hist.history[k] = np.concatenate([hist.history[k], _h.history[k]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4i5uWhCGpes"
      },
      "source": [
        "# Plot losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "PGWM_kL0vLTw",
        "outputId": "2cd7a883-7b8f-47b9-b451-133b5dd191a7"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(hist.history['loss'], label='loss')\n",
        "plt.plot(hist.history['val_loss'], label='val_loss')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlyQHx33DVBi"
      },
      "outputs": [],
      "source": [
        "resnext_model.save('../Models/model_tandem_forward.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
